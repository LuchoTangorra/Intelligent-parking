{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T19:59:05.954333Z",
     "start_time": "2019-12-31T19:59:02.528969Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Embedding, Concatenate, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from random import shuffle\n",
    "import datetime\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T19:59:05.962264Z",
     "start_time": "2019-12-31T19:59:05.955281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".output {\n",
       "    flex-direction: column;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "#Just to have each print in the same row\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    flex-direction: column;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "HTML('<style>{}</style>'.format(CSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T19:59:05.969244Z",
     "start_time": "2019-12-31T19:59:05.965256Z"
    }
   },
   "outputs": [],
   "source": [
    "r'''   \n",
    "data_w_operacion: (DataFrame) data with their corresponding operacion (Entrada/Salida).\n",
    "    path: C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data_w_operacion.csv\n",
    "\n",
    "'''\n",
    "\n",
    "data_path = r'C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data_w_operacion.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T19:59:05.977223Z",
     "start_time": "2019-12-31T19:59:05.971239Z"
    }
   },
   "outputs": [],
   "source": [
    "#Time intervals\n",
    "period = 3 #3 - 3\n",
    "\n",
    "#How much data we will use to feed the lstm\n",
    "train_size = 4 #7 - 4\n",
    "\n",
    "#How much different values we want as input of the LSTM (i.e. tolerance 3/train_size 5: 0,1,2,2,1)\n",
    "#Must be less or equals than train_size\n",
    "tolerance = 3 #5 - 3\n",
    "\n",
    "#which columns we'll use as input of the LSTM, features are how much colums we have\n",
    "data_columns = ['tiempo','ocupacion','operacion']\n",
    "features = len(data_columns)\n",
    "\n",
    "#if we want the target to be different to the last value of the data\n",
    "control_target = True\n",
    "\n",
    "dateweek_columns = ['id_cuadra','dia de semana', 'tiempo', 'ocupacion','operacion','estacion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.534Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, parse_dates=['fecha_tiempo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.539Z"
    }
   },
   "outputs": [],
   "source": [
    "data['dia de semana'] = data['fecha_tiempo'].apply(lambda x: pd.Timestamp(x).weekday())\n",
    "data['tiempo'] = data['tiempo'].apply(lambda x: pd.Timestamp(x).time())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.541Z"
    }
   },
   "outputs": [],
   "source": [
    "#Me quedo con los que estan entre las 8 y las 21hs\n",
    "data = data.loc[(data.tiempo > datetime.time(8)) & (data.tiempo < datetime.time(21))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.544Z"
    }
   },
   "outputs": [],
   "source": [
    "max_street_num = data.loc[:,'id_cuadra'].max()\n",
    "print('Max street id: ', max_street_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.546Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "La idea de la red seria que de input tenga fecha_tiempo (o por ahi mejor, solo dia de la semana), \n",
    "la ocupacion de esa fecha_tiempo, el clima.\n",
    "Como output deberia tener la ocupacion de ese momento.\n",
    "\n",
    "Aparte a todo eso se deberia ver la ocupacion actual y la ocupacion maxima para saber si hay lugar libre.\n",
    "'''\n",
    "\n",
    "def to_seconds(time):\n",
    "    '''transform datetime.time to seconds'''\n",
    "    return time.hour * 60 * 60 + time.minute * 60 + time.second\n",
    "\n",
    "def normalize_time(time):\n",
    "    '''normalize time (in seconds) to values bertween 0 and 1'''\n",
    "    max_time = 23 * 60 * 60 + 59 * 60 + 59\n",
    "    return time / max_time\n",
    "\n",
    "def modify_operation(operation):\n",
    "    '''if operacion == Entrada sets value to 1, == NaN sets to 0 and == Salida sets to -1'''\n",
    "    if operation == 'Entrada':\n",
    "        return 1\n",
    "    if operation == 'Salida':\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def normalize_ocupation(row):\n",
    "    '''normalize ocupation to values between 0 and 1, using the lugares_cuadra value'''\n",
    "    global max_ocup\n",
    "    return (row['ocupacion'] / max_ocup)\n",
    "\n",
    "def get_season(fecha):\n",
    "    fecha = pd.to_datetime(fecha, dayfirst=True)\n",
    "    d = fecha.day\n",
    "    m = fecha.month * 100\n",
    "    md = m + d\n",
    "    if ((md >= 921) and (md <= 1220)):\n",
    "        season = 0  # spring\n",
    "    elif ((md >= 1221) and (md <= 320)):\n",
    "        season = 1  # summer\n",
    "    elif ((md >= 321) and (md <= 620)):\n",
    "        season = 2  # fall\n",
    "    elif ((md >= 621) and (md <= 920)):\n",
    "        season = 3  # winter\n",
    "    return season\n",
    "\n",
    "data_week = data.loc[:, ['id_cuadra','dia de semana', 'tiempo', 'ocupacion','operacion','fecha']]\n",
    "data_week['tiempo'] = data_week['tiempo'].apply(to_seconds)\n",
    "data_week['operacion'] = data_week['operacion'].apply(modify_operation)\n",
    "data_week['estacion'] = data_week['fecha'].apply(get_season)\n",
    "\n",
    "max_ocup = data['lugares_cuadra'].max()\n",
    "data_week['ocupacion'] = data_week.apply(normalize_ocupation, axis=1)\n",
    "data_week = data_week.loc[:, dateweek_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.548Z"
    }
   },
   "outputs": [],
   "source": [
    "print('max_ocup: ', max_ocup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.552Z"
    }
   },
   "outputs": [],
   "source": [
    "data_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.555Z"
    }
   },
   "outputs": [],
   "source": [
    "#To obtain the start and finish of each day, usefull to normalize data times\n",
    "\n",
    "indexes = [0]\n",
    "\n",
    "total_len = 1\n",
    "\n",
    "x = data_week.reset_index()\n",
    "exit = False\n",
    "while (total_len > 0) and not exit:\n",
    "    total_len = len(x.loc[x.loc[indexes[-1]:, 'dia de semana'].drop_duplicates().index, 'index'])\n",
    "    try:\n",
    "        indexes.append(x.loc[x.loc[indexes[-1]:, 'dia de semana'].drop_duplicates().index, 'index'].iloc[1])\n",
    "    except:\n",
    "        exit = True\n",
    "        print('Work complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.558Z"
    }
   },
   "outputs": [],
   "source": [
    "#Suponiendo que me llega solo un df conteniendo un solo dia (y esto lo hago para todos los dias y para cada calle)\n",
    "def normalize_data_period(data, period=5):\n",
    "    '''\n",
    "        normalize data in periods for a day\n",
    "    '''\n",
    "    seconds = period * 60\n",
    "    out = pd.DataFrame(columns=dateweek_columns)\n",
    "    out = out.append(data.iloc[0])\n",
    "    dist_to_period = out.iloc[-1].tiempo % seconds\n",
    "    if (dist_to_period) != 0:\n",
    "        out.iloc[-1].tiempo = out.iloc[-1].tiempo - dist_to_period\n",
    "        \n",
    "    for i in range(math.ceil((data.iloc[-1].tiempo - data.iloc[0].tiempo) / seconds)):\n",
    "        next_period = data.loc[data.tiempo < (out.iloc[-1].tiempo+seconds)]\n",
    "        if (len(next_period) == 0):\n",
    "            out = out.append(out.iloc[-1])\n",
    "            out.iloc[-1].tiempo = out.iloc[-1] + seconds\n",
    "        else:\n",
    "            out = out.append(next_period.iloc[-1])\n",
    "            out.iloc[-1].tiempo = out.iloc[-2].tiempo + seconds\n",
    "        if ( out.iloc[-2].ocupacion == out.iloc[-1].ocupacion):\n",
    "            out.iloc[-1].operacion = 0\n",
    "    return out.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.560Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalizes all the data times. Divide the data into x minutes intervals\n",
    "normalized_data = pd.DataFrame(columns=dateweek_columns)\n",
    "for i in range(len(indexes)-1):\n",
    "    clear_output()\n",
    "    print('Iteracion {} de {}'.format(i, len(indexes)-2))\n",
    "    normalized_data = normalized_data.append(normalize_data_period(data_week[indexes[i]:indexes[i+1]].copy(), period=period) )\n",
    "normalized_data = normalized_data.append(normalize_data_period(data_week[indexes[-1]:len(data_week)].copy(), period=period) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.564Z"
    }
   },
   "outputs": [],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.566Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalize the tiempo column to values between 0 and 1\n",
    "normalized_data['tiempo'] = normalized_data['tiempo'].apply(normalize_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.568Z"
    }
   },
   "outputs": [],
   "source": [
    "def separate_data_per_street(data, street):\n",
    "    '''\n",
    "    Divide the df that contains all the streets into a list.\n",
    "    Which position contains a data of a designed street\n",
    "    '''\n",
    "    return data.loc[data.id_cuadra == street]\n",
    "\n",
    "data_separate = []\n",
    "for i in (normalized_data['id_cuadra'].drop_duplicates()):\n",
    "    data_separate.append(separate_data_per_street(normalized_data, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.575Z"
    }
   },
   "outputs": [],
   "source": [
    "data_separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.578Z"
    }
   },
   "outputs": [],
   "source": [
    "#este es el nuevo\n",
    "def prepare_train_data(data, street, train_size=3, tolerance=0, data_columns=['tiempo','ocupacion','operacion'], control_target=False):\n",
    "    '''\n",
    "    Puts train_size values in a row with \n",
    "    '''   \n",
    "    train_data = []\n",
    "    train_street = []\n",
    "    train_weekday = []\n",
    "    train_season = []\n",
    "    targets = []\n",
    "\n",
    "    #We dont have any value in sunday\n",
    "    for weekday in range(0, 6):\n",
    "        data_weekday = data.loc[data['dia de semana'] == weekday]\n",
    "        \n",
    "        for s in range(0, 4):\n",
    "            data_season = data_weekday.loc[data_weekday['estacion'] == s]\n",
    "\n",
    "            for i in range(len(data_season)-train_size-1):\n",
    "                data_to_add = data_season[i:i+train_size].loc[:, data_columns]\n",
    "                if len(data_to_add['ocupacion'].drop_duplicates()) >= tolerance:\n",
    "                    if (data_to_add['ocupacion'].iloc[train_size-1]) != (data_season.iloc[i+train_size+1]['ocupacion']):\n",
    "                        train_data.append(np.array(data_to_add.values)) \n",
    "                        train_street.append(street)\n",
    "                        train_weekday.append(weekday)\n",
    "                        train_season.append(s)\n",
    "                        targets.append(data_season.iloc[i+train_size+1]['ocupacion'])               \n",
    "\n",
    "        #TODO: delete train_time\n",
    "        #train_time.append(np.array(data_weekday[train_size:].loc[:,'tiempo'].values))\n",
    "\n",
    "    #return np.array(train_data), np.array(train_street), np.array(train_weekday), np.array(train_time), np.array(targets)\n",
    "    return np.array(train_data), np.array(train_street), np.array(train_weekday), np.array(train_season), np.array(targets)\n",
    "    \n",
    "        \n",
    "train_data = []\n",
    "train_street = []\n",
    "train_weekday = []\n",
    "train_season = []\n",
    "#train_time = []\n",
    "targets = []\n",
    "\n",
    "for street in range(len(normalized_data['id_cuadra'].drop_duplicates())):\n",
    "    clear_output()\n",
    "    print('Calle num: ', street)\n",
    "    #p_train_data, p_train_street, p_train_weekday, p_train_time, p_targets = prepare_train_data(data_separate[street], street, train_size=train_size, tolerance=tolerance, operation=operation, control_target=control_target)\n",
    "    p_train_data, p_train_street, p_train_weekday, p_train_season, p_targets = prepare_train_data(data_separate[street], street, train_size=train_size, tolerance=tolerance, data_columns=data_columns, control_target=control_target)\n",
    "    train_data.append(p_train_data)\n",
    "    train_street.append(p_train_street)\n",
    "    train_weekday.append(p_train_weekday)\n",
    "    train_season.append(p_train_season)\n",
    "    #train_time.append(p_train_time)\n",
    "    targets.append(p_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.580Z"
    }
   },
   "outputs": [],
   "source": [
    "'''# ESTE ANDA\n",
    "def prepare_train_data(data, street, train_size=3):\n",
    "    \n",
    "    #Puts train_size values in a row with \n",
    "      \n",
    "    train_data = []\n",
    "    train_street = []\n",
    "    train_weekday = []\n",
    "    train_time = []\n",
    "    targets = []\n",
    "\n",
    "    #We dont have any value in sunday\n",
    "    for weekday in range(0, 6):\n",
    "        data_weekday = data.loc[data['dia de semana'] == weekday]\n",
    "\n",
    "        for i in range(len(data_weekday)-train_size):\n",
    "            train_data.append(np.array(data_weekday[i:i+train_size].loc[:,['tiempo','ocupacion','operacion']].values)) \n",
    "            train_street.append(street)\n",
    "            train_weekday.append(weekday)\n",
    "\n",
    "        train_time.append(np.array(data_weekday[train_size:].loc[:,'tiempo'].values))\n",
    "        targets.append(np.array(data_weekday[train_size:].loc[:,'ocupacion'].values))               \n",
    "\n",
    "    return np.array(train_data), np.array(train_street), np.array(train_weekday), np.array(train_time), np.array(targets)\n",
    "    \n",
    "        \n",
    "train_data = []\n",
    "train_street = []\n",
    "train_weekday = []\n",
    "train_time = []\n",
    "targets = []\n",
    "\n",
    "for street in range(len(normalized_data['id_cuadra'].drop_duplicates())):\n",
    "    print('Calle num: ', street)\n",
    "    p_train_data, p_train_street, p_train_weekday, p_train_time, p_targets = prepare_train_data(data_separate[street], street, train_size=train_size)\n",
    "    train_data.append(p_train_data)\n",
    "    train_street.append(p_train_street)\n",
    "    train_weekday.append(p_train_weekday)\n",
    "    train_time.append(p_train_time)\n",
    "    targets.append(p_targets)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.583Z"
    }
   },
   "outputs": [],
   "source": [
    "'''train_street'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.585Z"
    }
   },
   "outputs": [],
   "source": [
    "'''train_data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.589Z"
    }
   },
   "outputs": [],
   "source": [
    "'''targets.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.591Z"
    }
   },
   "outputs": [],
   "source": [
    "#t_train_weekday.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.593Z"
    }
   },
   "outputs": [],
   "source": [
    "t_train_street = train_street[0]\n",
    "t_train_weekday = train_weekday[0]\n",
    "t_train_data = train_data[0]\n",
    "t_train_season = train_season[0]\n",
    "t_targets = targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.595Z"
    }
   },
   "outputs": [],
   "source": [
    "'''t_train_street = train_street\n",
    "t_train_weekday = train_weekday\n",
    "t_train_data = train_data\n",
    "t_train_season = train_season\n",
    "t_targets = targets'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.598Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_street) - 1):\n",
    "    t_train_street = np.concatenate([t_train_street, train_street[i+1]])\n",
    "    t_train_weekday = np.concatenate([t_train_weekday, train_weekday[i+1]])\n",
    "    t_train_season = np.concatenate([t_train_season, train_season[i+1]])\n",
    "    t_targets = np.concatenate([t_targets, targets[i+1]])\n",
    "\n",
    "empty_streets = []\n",
    "#try:\n",
    "for i in range(len(train_data) - 1):\n",
    "    clear_output()\n",
    "    print('Iteration: {} of {}'.format(i+1, len(train_data) - 1))\n",
    "    if len(train_data[i+1]) > 0:\n",
    "        t_train_data = np.concatenate([t_train_data, train_data[i+1]])\n",
    "    else:\n",
    "        empty_streets.append(i+1)\n",
    "#except:\n",
    "#    print('ValueError: all the input arrays must have same number of dimensions in data')\n",
    "print(empty_streets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.600Z"
    }
   },
   "outputs": [],
   "source": [
    "to_shuffle = list(zip(t_train_street, t_train_weekday, t_train_data, t_train_season, t_targets))\n",
    "shuffle(to_shuffle)\n",
    "s_train_street, s_train_weekday, s_train_data, s_train_season, s_targets = zip(*to_shuffle)\n",
    "\n",
    "s_targets = np.array(s_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.602Z"
    }
   },
   "outputs": [],
   "source": [
    "'''x = tf.random.shuffle(t_train_street, seed=5)\n",
    "y = tf.random.shuffle(t_train_weekday, seed=5)\n",
    "z = tf.random.shuffle(t_targets, seed=5)\n",
    "t = tf.random.shuffle(t_train_data, seed=5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.605Z"
    }
   },
   "outputs": [],
   "source": [
    "'''z'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.608Z"
    }
   },
   "outputs": [],
   "source": [
    "(t_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.610Z"
    }
   },
   "outputs": [],
   "source": [
    "t_train_street = tf.convert_to_tensor(s_train_street, np.float64)\n",
    "t_train_weekday = tf.convert_to_tensor(s_train_weekday, np.float64)\n",
    "t_train_data = tf.convert_to_tensor(s_train_data, np.float64)\n",
    "t_train_season = tf.convert_to_tensor(s_train_season, np.float64)\n",
    "t_targets = tf.convert_to_tensor(s_targets, np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.612Z"
    }
   },
   "outputs": [],
   "source": [
    "'''#Aplano todo y lo dejo para que entre a la red (elimino la division entre calles)\n",
    "train_street = [y for x in train_street for y in x]\n",
    "train_weekday = [y for x in train_weekday for y in x]\n",
    "train_data = [y for x in train_data for y in x]\n",
    "train_time = [y for x in train_time for y in x]\n",
    "train_time = [y for x in train_time for y in x]\n",
    "targets = [y for x in targets for y in x]\n",
    "targets = [y for x in targets for y in x]\n",
    "'''\n",
    "\n",
    "#VER COMO HACER QUE ESTO FUNCIONE\n",
    "'''\n",
    "to_shuffle = list(zip(train_street, train_weekday, train_data, train_time, targets))\n",
    "shuffle(to_shuffle)\n",
    "s_train_street, s_train_weekday, s_train_data, s_train_time, s_targets = zip(*to_shuffle)\n",
    "\n",
    "s_targets = np.array(s_targets)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.614Z"
    }
   },
   "outputs": [],
   "source": [
    "'''t_train_data'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.616Z"
    }
   },
   "outputs": [],
   "source": [
    "'''(t_targets)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.618Z"
    }
   },
   "outputs": [],
   "source": [
    "'''(s_train_weekday[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.620Z"
    }
   },
   "outputs": [],
   "source": [
    "'''(s_train_data)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.622Z"
    }
   },
   "outputs": [],
   "source": [
    "'''(s_train_time[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.627Z"
    }
   },
   "outputs": [],
   "source": [
    "'''(s_targets[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.630Z"
    }
   },
   "outputs": [],
   "source": [
    "street = 65\n",
    "weekday = 3\n",
    "\n",
    "\n",
    "plot_data = normalized_data.loc[(normalized_data.id_cuadra == street) & (normalized_data['dia de semana'] == weekday), ['tiempo', 'ocupacion']]\n",
    "plot_data = plot_data.groupby(by='tiempo').mean().reset_index()\n",
    "\n",
    "def denormalize_time(time):\n",
    "    max_time = 23 * 60 * 60 + 59 * 60 + 59\n",
    "    return pd.Timestamp(time * max_time, unit='s').time()\n",
    "\n",
    "def denormalize_ocupation(ocupation):\n",
    "    global max_ocup\n",
    "    return ocupation * max_ocup\n",
    "\n",
    "def clean_predictions(ocupation):\n",
    "    if ocupation <= 0:\n",
    "        return 0\n",
    "    return round(ocupation)\n",
    "\n",
    "\n",
    "plot_data['tiempo'] = plot_data['tiempo'].apply(denormalize_time)\n",
    "plot_data['ocupacion'] = plot_data['ocupacion'].apply(denormalize_ocupation)\n",
    "\n",
    "#Set the label titles\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Parked cars')\n",
    "plt.title('Average parked cars in street nº{} in day {}.'.format(street, weekday))\n",
    "\n",
    "#Set the plot data for each graph (ax1,ax2,ax3)\n",
    "plt.plot(plot_data['tiempo'], plot_data['ocupacion'])\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,8)\n",
    "plt.grid()\n",
    "#plt.xticks(normalized_data['fecha_hora'], time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.632Z"
    }
   },
   "outputs": [],
   "source": [
    "#Para la calle\n",
    "input_street = Input(shape=(1), name='input_street')\n",
    "#emb_street = Embedding(input_length=1, input_dim=max_street_num+1, output_dim=32)(input_street)\n",
    "emb_street = Embedding(input_length=1, input_dim=max_street_num+1, output_dim=32)(input_street)\n",
    "flat_street = Flatten()(emb_street)\n",
    "\n",
    "#Para el dia de la semana\n",
    "input_weekday = Input(shape=(1), name='input_weekday')\n",
    "#emb_weekday = Embedding(input_length=1, input_dim=7, output_dim=16)(input_weekday)\n",
    "emb_weekday = Embedding(input_length=1, input_dim=6, output_dim=8)(input_weekday)\n",
    "flat_weekday = Flatten()(emb_weekday)\n",
    "\n",
    "#Para el tiempo y la ocupacion y la operacion\n",
    "input_data = Input(shape=(train_size, features), name='input_data')\n",
    "#lstm = LSTM(16, return_sequences=False, recurrent_dropout=0.25)(input_data)\n",
    "lstm_layer = LSTM(16, return_sequences=True, recurrent_dropout=0.25)(input_data)\n",
    "lstm = LSTM(6, return_sequences=False, recurrent_dropout=0.25)(lstm_layer)\n",
    "\n",
    "#Para la estacion del año\n",
    "input_season = Input(shape=(1), name='input_season')\n",
    "emb_season = Embedding(input_length=1, input_dim=4, output_dim=4)(input_season)\n",
    "flat_season = Flatten()(emb_season)\n",
    "\n",
    "\n",
    "#Para el tiempo a predecir \n",
    "#No agrega valor, hace mas chota a la red. En vez de esto voy a arreglar el tiempo en los datos\n",
    "#y hacer que sea cada cierta cantidad de minutos siempre.\n",
    "#input_time = Input(shape=(1), name='input_time')\n",
    "\n",
    "concat = Concatenate(axis=-1)\n",
    "input_merge = concat([flat_weekday, flat_street])\n",
    "input_merge = concat([input_merge, lstm])\n",
    "input_merge = concat([input_merge, flat_season])\n",
    "#input_merge = concat([input_merge, input_time])\n",
    "\n",
    "d = Dense(32, activation='relu')(input_merge)\n",
    "d = Dropout(0.25)(d)\n",
    "#d = Dense(128, activation='relu')(d)\n",
    "#d = Dense(128, activation='relu')(d)\n",
    "#d = Dropout(0.5)(d)\n",
    "#d = Dense(128, activation='relu')(d)\n",
    "#d = Dense(128, activation='relu')(d)\n",
    "#d = Dense(128, activation='relu')(d)\n",
    "#d = Dropout(0.5)(d)\n",
    "#d = Dense(32, activation='relu')(d)\n",
    "#d = Dropout(0.25)(d)\n",
    "out = Dense(1, activation='linear')(d)\n",
    "\n",
    "model = Model(inputs=[input_weekday, input_street, input_season, input_data], outputs=out)\n",
    "model.summary()\n",
    "model.compile(loss='MSE', optimizer='adam', metrics=['MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.634Z"
    }
   },
   "outputs": [],
   "source": [
    "#h = model.fit([s_train_weekday, s_train_street, s_train_data], s_targets, epochs=5, batch_size=64, validation_split=0.1)\n",
    "red_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00000001)\n",
    "\n",
    "#h = model.fit([t_train_weekday, t_train_street, t_train_data], t_targets, epochs=20, batch_size=32, validation_split=0.2, callbacks=[red_lr])\n",
    "#h = model.fit([t_train_weekday, t_train_street, t_train_season, t_train_data], tf.map_fn(denormalize_ocupation, t_targets), epochs=20, batch_size=16, validation_split=0.2, callbacks=[red_lr])\n",
    "h = model.fit([t_train_weekday, t_train_street, t_train_season, t_train_data], t_targets, epochs=20, batch_size=8, validation_split=0.1, callbacks=[red_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.637Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(h.history['MAE'])\n",
    "plt.plot(h.history['val_MAE'])\n",
    "plt.title('model MAE')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.639Z"
    }
   },
   "outputs": [],
   "source": [
    "index = 2\n",
    "\n",
    "true_data = data_week[indexes[index]:indexes[index+1]].copy().reset_index(drop=True)\n",
    "true_data['tiempo'].apply(normalize_time).apply(denormalize_time).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.642Z"
    }
   },
   "outputs": [],
   "source": [
    "start_index = 43\n",
    "finish_index = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.645Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = true_data['tiempo'].iloc[start_index]\n",
    "finish_time = true_data['tiempo'].iloc[finish_index]\n",
    "predictions_needed = int((finish_time - start_time) / (period * 60))\n",
    "\n",
    "plot_true_data = true_data.copy()\n",
    "\n",
    "weekday = plot_true_data['dia de semana'][0]\n",
    "\n",
    "def denormalize_time_to_date(time):\n",
    "    return pd.Timestamp(time, unit='s').time()\n",
    "\n",
    "\n",
    "#print(start_index, finish_index)\n",
    "\n",
    "plot_true_data['tiempo'] = plot_true_data['tiempo'].apply(normalize_time)\n",
    "\n",
    "def init_test(data, data_columns=['tiempo','ocupacion','operacion']):\n",
    "    global train_size, features\n",
    "    #print(data)\n",
    "    street = data['id_cuadra'].iloc[0]\n",
    "    weekday = data['dia de semana'].iloc[0]\n",
    "    season = data['estacion'].iloc[0]\n",
    "    d = data[data_columns]\n",
    "    street = np.array(street).reshape(1,1)\n",
    "    weekday = np.array(street).reshape(1,1)\n",
    "    season = np.array(season).reshape(1,1)\n",
    "    d = np.array(d).reshape(1,train_size,features)\n",
    "    return street, weekday, season, d\n",
    "\n",
    "def prepare_test_data(data, predicted_data, predicted_time, data_columns=['tiempo','ocupacion','operacion']):\n",
    "    last = data[0]\n",
    "    if 'operacion' in data_columns:\n",
    "        last[-1]\n",
    "        print('TODO')\n",
    "    else:\n",
    "        #print(data[0])\n",
    "        #print(np.array([predicted_time,predicted_data]))\n",
    "        \n",
    "        #print(np.concatenate([data[0], np.array([predicted_time,predicted_data]).reshape(1,features)]))\n",
    "        \n",
    "        out = np.concatenate([data[0], np.array([predicted_time,predicted_data]).reshape(1,features)])\n",
    "        out = out[1:out.shape[0]].reshape(1, train_size, features)\n",
    "        #print(out)\n",
    "        #print(out.shape[1])\n",
    "    return out\n",
    "    \n",
    "#print(plot_true_data)\n",
    "\n",
    "\n",
    "test_street, test_weekday, test_season, test_data = init_test(plot_true_data[start_index-train_size+1:start_index+1], data_columns=data_columns)\n",
    "\n",
    "plot_predicted_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "last_data_time = test_data[0][test_data.shape[1]-1][0]\n",
    "\n",
    "plot_predicted_data = plot_predicted_data.append({'ocupacion':test_data[0][test_data.shape[1]-1][1], 'tiempo':last_data_time}, ignore_index=True)\n",
    "#plot_predicted_data = plot_predicted_data.append({'ocupacion':denormalize_ocupation(test_data[0][test_data.shape[1]-1][1]), 'tiempo':last_data_time}, ignore_index=True)\n",
    "\n",
    "#print(test_data)\n",
    "\n",
    "\n",
    "#print(to_seconds(denormalize_time(last_data_time)))\n",
    "for i in range(predictions_needed):\n",
    "    print('Iteration: {} of {}'.format(i, (predictions_needed)))\n",
    "          \n",
    "    pred_value = model.predict([test_street, test_weekday, test_season, test_data])[0][0]\n",
    "    pred_time = last_data_time + normalize_time(period * 60)\n",
    "    \n",
    "    #if i == 1 or i == 2 or i == 3:\n",
    "    #    print(pred_value)\n",
    "    \n",
    "    plot_predicted_data = plot_predicted_data.append({'ocupacion': pred_value, 'tiempo': pred_time}, ignore_index=True)\n",
    "    last_data_time = pred_time\n",
    "    test_data = prepare_test_data(test_data, predicted_data=pred_value, predicted_time=pred_time, data_columns=data_columns)\n",
    "\n",
    "\n",
    "plot_true_data['tiempo'] = plot_true_data['tiempo'].apply(denormalize_time)\n",
    "plot_true_data['ocupacion'] = plot_true_data['ocupacion'].apply(denormalize_ocupation)\n",
    "plot_predicted_data['tiempo'] = plot_predicted_data['tiempo'].apply(denormalize_time)\n",
    "plot_predicted_data['ocupacion'] = plot_predicted_data['ocupacion'].apply(denormalize_ocupation)\n",
    "plot_predicted_data['ocupacion'] = plot_predicted_data['ocupacion'].apply(clean_predictions)\n",
    "\n",
    "\n",
    "#Set the label titles\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Parked cars')\n",
    "plt.title('Average parked cars in street nº{} on {}.'.format(test_street[0][0], weekday))\n",
    "\n",
    "#Set the plot data for each graph (ax1,ax2,ax3)\n",
    "plt.plot(plot_true_data['tiempo'], plot_true_data['ocupacion'], c='b')\n",
    "plt.plot(plot_predicted_data['tiempo'], plot_predicted_data['ocupacion'], c='r')\n",
    "\n",
    "clear_output()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,8)\n",
    "plt.grid()\n",
    "plt.legend(['True values','Predicted values'])\n",
    "#plt.xticks(normalized_data['fecha_hora'], time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.648Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.651Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "a = np.array(t_train_weekday[i])\n",
    "a = np.reshape(a, (1,1))\n",
    "\n",
    "b = np.array(t_train_street[i])\n",
    "b = np.reshape(b, (1,1))\n",
    "\n",
    "c = np.array(t_train_season[i])\n",
    "c = np.reshape(c, (1,1))\n",
    "#c = np.array(train_time[0][0])\n",
    "#c = np.reshape(c, (1,1))\n",
    "\n",
    "d = np.array(t_train_data[i])\n",
    "d = np.reshape(d, (1,train_size,features))\n",
    "d = tf.convert_to_tensor(d, np.float64)\n",
    "\n",
    "not_normalized_data = []\n",
    "\n",
    "for i in range(train_size):\n",
    "    not_normalized_data.append(float(d[0][i][1]) * max_ocup)\n",
    "    \n",
    "    \n",
    "print('Weekday: ', a[0])\n",
    "print('Street:  ', b[0])\n",
    "print('Season:    ', c[0])\n",
    "print('Data:    ', d[0])\n",
    "print('Not normalized data: ', not_normalized_data)\n",
    "print('Targets: ', t_targets[i])\n",
    "print('Targets: ', t_targets[i] * max_ocup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.653Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Valor predicho: ', model.predict([a, b, c, d])[0][0])\n",
    "print('Valor predicho (si normalizar es necesario): ', model.predict([a, b, c, d])[0][0] * max_ocup)\n",
    "\n",
    "import math #funcion techo\n",
    "#print('Valor predicho techo: ', math.ceil(model.predict([a, b, d])[0][0]))\n",
    "\n",
    "print('Valor real:     ', t_targets[i] * max_ocup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-31T19:59:02.656Z"
    }
   },
   "outputs": [],
   "source": [
    "'''index = 1\n",
    "\n",
    "\n",
    "plot_true_data = data_week[indexes[index]:indexes[index+1]].copy().reset_index(drop=True)\n",
    "\n",
    "weekday = plot_true_data['dia de semana'][0]\n",
    "def denormalize_time_to_date(time):\n",
    "    return pd.Timestamp(time, unit='s').time()\n",
    "\n",
    "quarter = int(len(plot_true_data) * 1/4)\n",
    "three_quarter = int(quarter * 3)\n",
    "\n",
    "#three_quarter_time = plot_true_data.iloc[three_quarter]['tiempo']\n",
    "\n",
    "plot_true_data['tiempo'] = plot_true_data['tiempo'].apply(normalize_time)\n",
    "\n",
    "def init_test(data, data_columns=['tiempo','ocupacion','operacion']):\n",
    "    global train_size, features\n",
    "    street = data['id_cuadra'].iloc[0]\n",
    "    weekday = data['dia de semana'].iloc[0]\n",
    "    season = data['estacion'].iloc[0]\n",
    "    d = data[data_columns]\n",
    "    street = np.array(street).reshape(1,1)\n",
    "    weekday = np.array(street).reshape(1,1)\n",
    "    season = np.array(season).reshape(1,1)\n",
    "    d = np.array(d).reshape(1,train_size,features)\n",
    "    return street, weekday, season, d\n",
    "\n",
    "def prepare_test_data(data, predicted_data, predicted_time, data_columns=['tiempo','ocupacion','operacion']):\n",
    "    last = data[0]\n",
    "    if 'operacion' in data_columns:\n",
    "        last[-1]\n",
    "        print('TODO')\n",
    "    else:\n",
    "        #print(data[0])\n",
    "        #print(np.array([predicted_time,predicted_data]))\n",
    "        \n",
    "        #print(np.concatenate([data[0], np.array([predicted_time,predicted_data]).reshape(1,features)]))\n",
    "        \n",
    "        out = np.concatenate([data[0], np.array([predicted_time,predicted_data]).reshape(1,features)])\n",
    "        out = out[1:out.shape[0]].reshape(1, train_size, features)\n",
    "        #print(out)\n",
    "        #print(out.shape[1])\n",
    "    return out\n",
    "    \n",
    "#print(plot_true_data)\n",
    "\n",
    "test_street, test_weekday, test_season, test_data = init_test(plot_true_data[-train_size-1-quarter:-1-quarter], data_columns=data_columns)\n",
    "\n",
    "plot_predicted_data = pd.DataFrame(columns=data_columns)\n",
    "\n",
    "last_data_time = test_data[0][test_data.shape[1]-1][0]\n",
    "\n",
    "plot_predicted_data = plot_predicted_data.append({'ocupacion':test_data[0][test_data.shape[1]-1][1], 'tiempo':last_data_time}, ignore_index=True)\n",
    "#plot_predicted_data = plot_predicted_data.append({'ocupacion':denormalize_ocupation(test_data[0][test_data.shape[1]-1][1]), 'tiempo':last_data_time}, ignore_index=True)\n",
    "\n",
    "print(test_data)\n",
    "\n",
    "for i in range(len(plot_true_data)-quarter):\n",
    "    print('Iteration: {} of {}'.format(i, len(plot_true_data)-quarter-1))\n",
    "\n",
    "    pred_value = model.predict([test_street, test_weekday, test_season, test_data])[0][0]\n",
    "    pred_time = last_data_time + normalize_time(period * 60)\n",
    "    \n",
    "    #if i == 1 or i == 2 or i == 3:\n",
    "    #    print(pred_value)\n",
    "    \n",
    "    plot_predicted_data = plot_predicted_data.append({'ocupacion': pred_value, 'tiempo': pred_time}, ignore_index=True)\n",
    "    last_data_time = pred_time\n",
    "    test_data = prepare_test_data(test_data, predicted_data=pred_value, predicted_time=pred_time, data_columns=data_columns)\n",
    "\n",
    "\n",
    "plot_true_data['tiempo'] = plot_true_data['tiempo'].apply(denormalize_time)\n",
    "plot_true_data['ocupacion'] = plot_true_data['ocupacion'].apply(denormalize_ocupation)\n",
    "plot_predicted_data['tiempo'] = plot_predicted_data['tiempo'].apply(denormalize_time)\n",
    "plot_predicted_data['ocupacion'] = plot_predicted_data['ocupacion'].apply(denormalize_ocupation)\n",
    "plot_predicted_data['ocupacion'] = plot_predicted_data['ocupacion'].apply(clean_predictions)\n",
    "\n",
    "\n",
    "#Set the label titles\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Parked cars')\n",
    "plt.title('Average parked cars in street nº{} on {}.'.format(test_street[0][0], weekday))\n",
    "\n",
    "#Set the plot data for each graph (ax1,ax2,ax3)\n",
    "plt.plot(plot_true_data['tiempo'], plot_true_data['ocupacion'], c='b')\n",
    "plt.plot(plot_predicted_data['tiempo'], plot_predicted_data['ocupacion'], c='r')\n",
    "\n",
    "clear_output()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,8)\n",
    "plt.grid()\n",
    "plt.legend(['True values','Predicted values'])\n",
    "#plt.xticks(normalized_data['fecha_hora'], time)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para el siguiente valor (y simular calcular valores seguidos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este intento voy a utilizar como dato de tiempo el dia con num y la hora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otra red!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas de redes:\n",
    "### Cosas que deberian ir si o si de entrada: Dia de la semana, mes (cuando tenga mas datos), tiempo\n",
    "### Utilizar los valores de Entrada/Salida y que prediga capacidad \n",
    "### Utilizar valores de capacidad y que prediga capacidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
