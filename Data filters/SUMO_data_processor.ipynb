{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before doing all of this, be sure of copy the data from the server, then delete it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'''\n",
    "data: (DataFrame) raw data from the csv obtained by the scraper (without any possible duplicated data)\n",
    "    path: C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data.csv\n",
    "\n",
    "data_w_operacion: (DataFrame) data with the corresponding operacion (Entrada/Salida).\n",
    "    path: C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data_w_operacion.csv\n",
    "\n",
    "old_data_idx: (DataFrame) last index for the old SUMO_data files\n",
    "    path: C:\\Users\\ing_l\\Tesis grado\\Data\\old_SUMO_data\\SUMO_data_index.txt\n",
    "'''\n",
    "\n",
    "data_path = r'C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data.csv'\n",
    "\n",
    "#Because we want to save all the data in the same file\n",
    "data_w_operacion_path = r'C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data_w_operacion.csv'\n",
    "    \n",
    "old_data_idx_path = r'C:\\Users\\ing_l\\Tesis grado\\Data\\old_SUMO_data\\SUMO_data_index.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlast_readed_row = np.nan\\nif os.path.isfile(last_readed_row_path):\\n    #We have saved it as dataframe column, so we need to extract it and\\n    #convert it to int64 numpy var.\\n    last_readed_row = pd.read_csv(last_readed_row_path).columns.values[1]\\n    last_readed_row = np.int64(last_readed_row)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the data from the data_path\n",
    "data = pd.read_csv(data_path, delimiter=',', parse_dates=[['fecha', 'tiempo']])\n",
    "    \n",
    "#Get the last row readed to start from there to read the data\n",
    "data_columns = np.append(data.columns.values, 'operacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if not np.isnan(last_readed_row):\\n    data = data.loc[data.index > last_readed_row]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort values so it will be easy to filter the data\n",
    "data = data.sort_values(['id_cuadra','fecha_tiempo'])\n",
    "\n",
    "#Drop duplicates if exists (not usefull data)\n",
    "data.drop_duplicates(['id_cuadra','fecha_tiempo'], keep='first', inplace=True)\n",
    "\n",
    "#Only maintain the green (usefull) values\n",
    "data = data.loc[data['dispon_parq'] == 'green'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_row_w_operation(row, operacion, ocupacion=None, time=None, infor=False):\n",
    "    '''\n",
    "    Create a new row who is a copy of the actual row with a new column\n",
    "    called operacion, a new fecha_tiempo if time!=None.\n",
    "    If you are in a loop put infor=True except for one value.\n",
    "    Put the current ocupacion of the street if infor=True, otherwise \n",
    "    can return unexpected results.\n",
    "    \n",
    "    Parameters:\n",
    "        row: (Series or DataFrame)current row to add a new column called operacion\n",
    "        operacion: (None, Entrada, Salida) the operacion we will add to the row\n",
    "        ocupacion: (int) if infor=True and ocupacion!=None the new row will contain this data\n",
    "        time: (timestamp) new time to be setted in fecha_tiempo of the new row\n",
    "        infor: (boolean) if you are in a for or not, put it false in the first or last iteration\n",
    "            of the loop.\n",
    "            \n",
    "    Return:\n",
    "        new_row: (Series or DataFrame, depends on row) the new row with the needed data\n",
    "    '''\n",
    "    \n",
    "    new_row = row.copy()\n",
    "    new_row['operacion'] = operacion\n",
    "    #If hours is a value, update it\n",
    "    if time != None:\n",
    "        new_row['fecha_tiempo'] = time\n",
    "    if infor == True:\n",
    "        if ocupacion != None:\n",
    "            if operacion == 'Entrada':\n",
    "                ocupacion = ocupacion + 1\n",
    "                new_row['ocupacion'] = ocupacion\n",
    "            elif operacion == 'Salida':\n",
    "                ocupacion = ocupacion - 1\n",
    "                new_row['ocupacion'] = ocupacion\n",
    "            return new_row, ocupacion\n",
    "    return new_row\n",
    "\n",
    "\n",
    "def get_aproximate_time(time1, time2, div, it):\n",
    "    '''\n",
    "    Heuristically get the time of the data that doesnt have time\n",
    "    \n",
    "    Parameters:\n",
    "        time1: (Timestamp) the time of the first row (less than time2)\n",
    "        time2: (Timestamp) the time of the second row (more than time1)\n",
    "        div: (int) total range of the loop \n",
    "        it: (int) number of iteration in the loop\n",
    "    \n",
    "    Returns:\n",
    "        new_time: the new time for the new row\n",
    "    '''\n",
    "    \n",
    "    #To get the difference in minutes from time1 and time2. \n",
    "    times_subs = time2 - time1\n",
    "    times_subs = times_subs / np.timedelta64(1,'m')\n",
    "    \n",
    "    #Get only the fraction to subs and multiply by the number of iteration\n",
    "    fraction_to_subs = times_subs / div\n",
    "    to_subs = int(fraction_to_subs * (div-it))\n",
    "    \n",
    "    #Substract the minutes to subs\n",
    "    if time2.minute-to_subs > 0:\n",
    "        new_time = time2.replace(minute=time2.minute-to_subs)\n",
    "    else:\n",
    "        new_time = time2.replace(minute=0, second=0)\n",
    "    return new_time\n",
    "\n",
    "\n",
    "def get_data_w_operacion():\n",
    "    '''\n",
    "    Process and returns the data with their operacion seen\n",
    "    in the DATA_sumo.csv\n",
    "    \n",
    "    Returns:\n",
    "        out_data: (DataFrame) the data processed with their operation\n",
    "    '''\n",
    "    \n",
    "    #All the columns from data plus the column 'operacion'\n",
    "    data_columns = np.append(data.columns.values, 'operacion')\n",
    "\n",
    "    #Initialize out_data (all the trusted rows) and last_row (last row we've visited)\n",
    "    out_data = pd.DataFrame(columns=data_columns)\n",
    "    last_row = pd.DataFrame(columns=data_columns)\n",
    "    \n",
    "    #Iterate over all the preprocessed data\n",
    "    for i, row in data.iterrows():        \n",
    "        \n",
    "        #Only usefull in the for inside\n",
    "        operacion = None\n",
    "        \n",
    "        \n",
    "        #If last row is empty we are in a new street (a new id_cuadra)\n",
    "        if last_row.empty:\n",
    "            last_row = create_row_w_operation(row, None)\n",
    "            out_data = out_data.append(last_row)\n",
    "        \n",
    "        #We are seeing rows representing the same street\n",
    "        else:\n",
    "            \n",
    "            #If last_row and row have a different id_cuadra means that we need\n",
    "            #to restart because we are now in a different street\n",
    "            if last_row['id_cuadra'] != row['id_cuadra']:\n",
    "                last_row = create_row_w_operation(row, None)\n",
    "                out_data = out_data.append(last_row) \n",
    "                \n",
    "            #Now we are in the same street (in last_row and row)\n",
    "            else:\n",
    "                \n",
    "                #Heuristic to have different time in each of the rows created in the for\n",
    "                first_time = last_row['fecha_tiempo']\n",
    "                last_time = row['fecha_tiempo']\n",
    "                \n",
    "                #We will need it in case we have for > 1\n",
    "                last_ocup = last_row['ocupacion']\n",
    "                \n",
    "                #For every difference in ocupacion...\n",
    "                #e.g. last_row[ocup] = 6, row[ocup] = 3\n",
    "                #we iterate 3 times and add 3 new rows with operacion Salida\n",
    "                dif_in_ocupacion = abs(int(last_row['ocupacion'])-int(row['ocupacion'])) + 1\n",
    "                for i in range(1, dif_in_ocupacion):\n",
    "                    \n",
    "                    #Get the aproximate time for the new row (in case we create one, for > 1)\n",
    "                    aprox_time = get_aproximate_time(first_time, last_time, dif_in_ocupacion, i)\n",
    "                    \n",
    "                    #If now we have more ocupacion than before, we have an Entrada\n",
    "                    if int(last_row['ocupacion']) < int(row['ocupacion']):\n",
    "                        operacion = 'Entrada'\n",
    "\n",
    "                    #If now we have less ocupacion than before, we have a Salida\n",
    "                    elif int(last_row['ocupacion']) > int(row['ocupacion']):\n",
    "                        operacion = 'Salida'\n",
    "                        \n",
    "                    #For each row we create in the for (for > 1) we change the hour\n",
    "                    #of the row to have better data\n",
    "                    if i < abs(int(last_row['ocupacion'])-int(row['ocupacion'])):\n",
    "                        aprox_time_row, last_ocup = create_row_w_operation(last_row, operacion, ocupacion=last_ocup, time=aprox_time, infor=True)\n",
    "                    #If we are in the last iteration of the for or we havent\n",
    "                    #created any row, we add it without changing it ocupacion\n",
    "                    #neither hora_fecha\n",
    "                    else:\n",
    "                        aprox_time_row = create_row_w_operation(row, operacion, infor=False)\n",
    "                    out_data = out_data.append(aprox_time_row)\n",
    "                last_row = create_row_w_operation(row, operacion)\n",
    "\n",
    "    return (out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all the data...\n",
      "Job complete!\n"
     ]
    }
   ],
   "source": [
    "print('Processing all the data...')\n",
    "\n",
    "data_w_operacion = get_data_w_operacion()\n",
    "\n",
    "print('Job complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the new trusted data and the last readed row...\n",
      "Saved succesfully!\n"
     ]
    }
   ],
   "source": [
    "print('Saving the new trusted data and the last readed row...')\n",
    "\n",
    "#If exists we dont want to overwrite it, so we append the new data\n",
    "if os.path.isfile(data_w_operacion_path):\n",
    "    data_w_operacion.to_csv(data_w_operacion_path, index=False, mode='a', header=False)\n",
    "else: #If it doesnt exists we create it\n",
    "    data_w_operacion.to_csv(data_w_operacion_path, index=False, header=data_w_operacion.columns.values)\n",
    "\n",
    "print('Saved succesfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the index of the new SUMO_data.csv file, to move it into a new folder.\n",
    "if not os.path.isfile(old_data_idx_path):\n",
    "    f = open(old_data_idx_path, \"w+\")\n",
    "    f.write('0')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(old_data_idx_path, \"r\")\n",
    "old_data_index = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move into another folder\n",
    "os.rename(data_path, \n",
    "          r'C:\\Users\\ing_l\\Tesis grado\\Data\\old_SUMO_data\\SUMO_data_' + old_data_index + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#save the new index (old + 1)\n",
    "f = open(old_data_idx_path, 'w')\n",
    "old_data_index = str(int(old_data_index) + 1)\n",
    "f.write(old_data_index)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
