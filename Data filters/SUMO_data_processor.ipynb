{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before doing all of this, be sure of copy the data from the server, then delete it from there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:31:14.778174Z",
     "start_time": "2019-10-15T17:31:13.183517Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:31:14.785083Z",
     "start_time": "2019-10-15T17:31:14.781094Z"
    }
   },
   "outputs": [],
   "source": [
    "r'''\n",
    "data: (DataFrame) raw data from the csv obtained by the scraper (without any possible duplicated data)\n",
    "    path: C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data.csv\n",
    "\n",
    "data_w_operacion: (DataFrame) data with the corresponding operacion (Entrada/Salida).\n",
    "    path: C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data_w_operacion.csv\n",
    "\n",
    "old_data_idx: (DataFrame) last index for the old SUMO_data files\n",
    "    path: C:\\Users\\ing_l\\Tesis grado\\Data\\old_SUMO_data\\SUMO_data_index.txt\n",
    "'''\n",
    "\n",
    "data_path = r'C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data.csv'\n",
    "\n",
    "#Because we want to save all the data in the same file\n",
    "data_w_operacion_path = r'C:\\Users\\ing_l\\Tesis grado\\Data\\SUMO_data_w_operacion.csv'\n",
    "    \n",
    "old_data_idx_path = r'C:\\Users\\ing_l\\Tesis grado\\Data\\old_SUMO_data\\SUMO_data_index.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:31:21.423178Z",
     "start_time": "2019-10-15T17:31:14.787079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read the data from the data_path\n",
    "data = pd.read_csv(data_path, delimiter=',', parse_dates=[['fecha', 'tiempo']])\n",
    "    \n",
    "#Get the last row readed to start from there to read the data\n",
    "data_columns = np.append(data.columns.values, 'operacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:31:21.498031Z",
     "start_time": "2019-10-15T17:31:21.426123Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sort values so it will be easy to see how to filter the data\n",
    "data = data.sort_values(['id_cuadra','fecha_tiempo'])\n",
    "\n",
    "#Drop duplicates if exists (not usefull data)\n",
    "data.drop_duplicates(['id_cuadra','fecha_tiempo'], keep='first', inplace=True)\n",
    "\n",
    "#Only maintain the green (usefull) values\n",
    "data = data.loc[data['dispon_parq'] == 'green'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:31:21.517978Z",
     "start_time": "2019-10-15T17:31:21.499989Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_row_w_operation(row, operacion, ocupacion=None, time=None, infor=False):\n",
    "    '''\n",
    "    Create a new row who is a copy of the actual row with a new column\n",
    "    called operacion, a new fecha_tiempo if time!=None.\n",
    "    If you are in a loop put infor=True except for one value.\n",
    "    Put the current ocupacion of the street if infor=True, otherwise \n",
    "    can return unexpected results.\n",
    "    \n",
    "    Parameters:\n",
    "        row: (Series or DataFrame)current row to add a new column called operacion\n",
    "        operacion: (None, Entrada, Salida) the operacion we will add to the row\n",
    "        ocupacion: (int) if infor=True and ocupacion!=None the new row will contain this data\n",
    "        time: (timestamp) new time to be setted in fecha_tiempo of the new row\n",
    "        infor: (boolean) if you are in a for or not, put it false in the first or last iteration\n",
    "            of the loop.\n",
    "            \n",
    "    Return:\n",
    "        new_row: (Series or DataFrame, depends on row) the new row with the needed data\n",
    "    '''\n",
    "    \n",
    "    new_row = row.copy()\n",
    "    new_row['operacion'] = operacion\n",
    "    #If hours is a value, update it\n",
    "    if time != None:\n",
    "        new_row['fecha_tiempo'] = time\n",
    "    if infor == True:\n",
    "        if ocupacion != None:\n",
    "            if operacion == 'Entrada':\n",
    "                ocupacion = ocupacion + 1\n",
    "                new_row['ocupacion'] = ocupacion\n",
    "            elif operacion == 'Salida':\n",
    "                ocupacion = ocupacion - 1\n",
    "                new_row['ocupacion'] = ocupacion\n",
    "            return new_row, ocupacion\n",
    "    return new_row\n",
    "\n",
    "\n",
    "def get_aproximate_time(time1, time2, div, it):\n",
    "    '''\n",
    "    Heuristically get the time of the data that doesnt have time\n",
    "    \n",
    "    Parameters:\n",
    "        time1: (Timestamp) the time of the first row (less than time2)\n",
    "        time2: (Timestamp) the time of the second row (more than time1)\n",
    "        div: (int) total range of the loop \n",
    "        it: (int) number of iteration in the loop\n",
    "    \n",
    "    Returns:\n",
    "        new_time: the new time for the new row\n",
    "    '''\n",
    "    \n",
    "    #To get the difference in minutes from time1 and time2. \n",
    "    times_subs = time2 - time1\n",
    "    times_subs = times_subs / np.timedelta64(1,'m')\n",
    "    \n",
    "    #Get only the fraction to subs and multiply by the number of iteration\n",
    "    fraction_to_subs = times_subs / div\n",
    "    to_subs = int(fraction_to_subs * (div-it))\n",
    "    \n",
    "    #Substract the minutes to subs\n",
    "    if time2.minute-to_subs > 0:\n",
    "        new_time = time2.replace(minute=time2.minute-to_subs)\n",
    "    else:\n",
    "        new_time = time2.replace(minute=0, second=0)\n",
    "    return new_time\n",
    "\n",
    "\n",
    "def get_data_w_operacion():\n",
    "    '''\n",
    "    Process and returns the data with their operacion seen\n",
    "    in the DATA_sumo.csv\n",
    "    \n",
    "    Returns:\n",
    "        out_data: (DataFrame) the data processed with their operation\n",
    "    '''\n",
    "    \n",
    "    #All the columns from data plus the column 'operacion'\n",
    "    data_columns = np.append(data.columns.values, 'operacion')\n",
    "\n",
    "    #Initialize out_data (all the trusted rows) and last_row (last row we've visited)\n",
    "    out_data = pd.DataFrame(columns=data_columns)\n",
    "    last_row = pd.DataFrame(columns=data_columns)\n",
    "    \n",
    "    #Iterate over all the preprocessed data\n",
    "    for i, row in data.iterrows():        \n",
    "        \n",
    "        #Only usefull inside the for\n",
    "        operacion = None\n",
    "        \n",
    "        \n",
    "        #If last row is empty we are in a new street (a new id_cuadra)\n",
    "        if last_row.empty:\n",
    "            last_row = create_row_w_operation(row, None)\n",
    "            out_data = out_data.append(last_row)\n",
    "        \n",
    "        #We are seeing rows representing the same street\n",
    "        else:\n",
    "            \n",
    "            #If last_row and row have a different id_cuadra means that we need\n",
    "            #to restart because we are now in a different street\n",
    "            if last_row['id_cuadra'] != row['id_cuadra']:\n",
    "                last_row = create_row_w_operation(row, None)\n",
    "                out_data = out_data.append(last_row) \n",
    "                \n",
    "            #Now we are in the same street (in last_row and row)\n",
    "            else:\n",
    "                \n",
    "                #Heuristic to have different time in each of the rows created in the for\n",
    "                first_time = last_row['fecha_tiempo']\n",
    "                last_time = row['fecha_tiempo']\n",
    "                \n",
    "                #We will need it in case we have for > 1\n",
    "                last_ocup = last_row['ocupacion']\n",
    "                \n",
    "                #For every difference in ocupacion...\n",
    "                #e.g. last_row[ocup] = 6, row[ocup] = 3\n",
    "                #we iterate 3 times and add 3 new rows with operacion Salida\n",
    "                dif_in_ocupacion = abs(int(last_row['ocupacion'])-int(row['ocupacion'])) + 1\n",
    "                for i in range(1, dif_in_ocupacion):\n",
    "                    \n",
    "                    #Get the aproximate time for the new row (in case we create one, for > 1)\n",
    "                    aprox_time = get_aproximate_time(first_time, last_time, dif_in_ocupacion, i)\n",
    "                    \n",
    "                    #If now we have more ocupacion than before, we have an Entrada\n",
    "                    if int(last_row['ocupacion']) < int(row['ocupacion']):\n",
    "                        operacion = 'Entrada'\n",
    "\n",
    "                    #If now we have less ocupacion than before, we have a Salida\n",
    "                    elif int(last_row['ocupacion']) > int(row['ocupacion']):\n",
    "                        operacion = 'Salida'\n",
    "                        \n",
    "                    #For each row we create in the for (for > 1) we change the hour\n",
    "                    #of the row to have better data\n",
    "                    if i < abs(int(last_row['ocupacion'])-int(row['ocupacion'])):\n",
    "                        aprox_time_row, last_ocup = create_row_w_operation(last_row, operacion, ocupacion=last_ocup, time=aprox_time, infor=True)\n",
    "                    #If we are in the last iteration of the for or we havent\n",
    "                    #created any row, we add it without changing it ocupacion\n",
    "                    #neither hora_fecha\n",
    "                    else:\n",
    "                        aprox_time_row = create_row_w_operation(row, operacion, infor=False)\n",
    "                    out_data = out_data.append(aprox_time_row)\n",
    "                last_row = create_row_w_operation(row, operacion)\n",
    "\n",
    "    return (out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:58:44.884846Z",
     "start_time": "2019-10-15T17:31:21.519936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all the data...\n",
      "Job complete!\n"
     ]
    }
   ],
   "source": [
    "print('Processing all the data...')\n",
    "\n",
    "data_w_operacion = get_data_w_operacion()\n",
    "\n",
    "print('Job complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:58:45.323687Z",
     "start_time": "2019-10-15T17:58:44.886841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the new trusted data and the last readed row...\n",
      "Saved succesfully!\n"
     ]
    }
   ],
   "source": [
    "print('Saving the new trusted data and the last readed row...')\n",
    "\n",
    "#If exists we dont want to overwrite it, so we append the new data\n",
    "if os.path.isfile(data_w_operacion_path):\n",
    "    data_w_operacion.to_csv(data_w_operacion_path, index=False, mode='a', header=False)\n",
    "else: #If it doesnt exists we create it\n",
    "    data_w_operacion.to_csv(data_w_operacion_path, index=False, header=data_w_operacion.columns.values)\n",
    "\n",
    "print('Saved succesfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:58:45.332731Z",
     "start_time": "2019-10-15T17:58:45.325668Z"
    }
   },
   "outputs": [],
   "source": [
    "#Saving the index of the new SUMO_data.csv file, to move it into a new folder.\n",
    "if not os.path.isfile(old_data_idx_path):\n",
    "    f = open(old_data_idx_path, \"w+\")\n",
    "    f.write('0')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:58:45.340628Z",
     "start_time": "2019-10-15T17:58:45.334644Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open(old_data_idx_path, \"r\")\n",
    "old_data_index = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:58:45.346625Z",
     "start_time": "2019-10-15T17:58:45.342622Z"
    }
   },
   "outputs": [],
   "source": [
    "#move into another folder\n",
    "os.rename(data_path, \n",
    "          r'C:\\Users\\ing_l\\Tesis grado\\Data\\old_SUMO_data\\SUMO_data_' + old_data_index + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:58:45.354592Z",
     "start_time": "2019-10-15T17:58:45.347609Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#save the new index (old + 1)\n",
    "f = open(old_data_idx_path, 'w')\n",
    "old_data_index = str(int(old_data_index) + 1)\n",
    "f.write(old_data_index)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T17:58:45.572035Z",
     "start_time": "2019-10-15T17:58:45.356612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_tiempo</th>\n",
       "      <th>id_cuadra</th>\n",
       "      <th>direccion</th>\n",
       "      <th>ocupacion</th>\n",
       "      <th>lugares_cuadra</th>\n",
       "      <th>ocupacion_max</th>\n",
       "      <th>dispon_parq</th>\n",
       "      <th>altas_bajas(dia)</th>\n",
       "      <th>operacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-13 07:48:01</td>\n",
       "      <td>2</td>\n",
       "      <td>General Pinto 545</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-13 08:48:04</td>\n",
       "      <td>2</td>\n",
       "      <td>General Pinto 545</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>4</td>\n",
       "      <td>Entrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-13 08:51:43</td>\n",
       "      <td>2</td>\n",
       "      <td>General Pinto 545</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>5</td>\n",
       "      <td>Salida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-09-13 09:25:06</td>\n",
       "      <td>2</td>\n",
       "      <td>General Pinto 545</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>6</td>\n",
       "      <td>Entrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-13 09:39:36</td>\n",
       "      <td>2</td>\n",
       "      <td>General Pinto 545</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>7</td>\n",
       "      <td>Entrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150785</td>\n",
       "      <td>2019-12-10 12:04:49</td>\n",
       "      <td>99</td>\n",
       "      <td>Av. España 970</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>8</td>\n",
       "      <td>Salida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150786</td>\n",
       "      <td>2019-12-10 12:07:17</td>\n",
       "      <td>99</td>\n",
       "      <td>Av. España 970</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>9</td>\n",
       "      <td>Entrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150787</td>\n",
       "      <td>2019-12-10 12:15:42</td>\n",
       "      <td>99</td>\n",
       "      <td>Av. España 970</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>11</td>\n",
       "      <td>Salida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150788</td>\n",
       "      <td>2019-12-10 18:16:57</td>\n",
       "      <td>99</td>\n",
       "      <td>Av. España 970</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>12</td>\n",
       "      <td>Entrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150789</td>\n",
       "      <td>2019-12-10 18:47:34</td>\n",
       "      <td>99</td>\n",
       "      <td>Av. España 970</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>13</td>\n",
       "      <td>Salida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150790 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               fecha_tiempo  id_cuadra          direccion  ocupacion  \\\n",
       "0       2019-09-13 07:48:01          2  General Pinto 545          1   \n",
       "1       2019-09-13 08:48:04          2  General Pinto 545          2   \n",
       "2       2019-09-13 08:51:43          2  General Pinto 545          1   \n",
       "3       2019-09-13 09:25:06          2  General Pinto 545          2   \n",
       "4       2019-09-13 09:39:36          2  General Pinto 545          3   \n",
       "...                     ...        ...                ...        ...   \n",
       "150785  2019-12-10 12:04:49         99     Av. España 970          0   \n",
       "150786  2019-12-10 12:07:17         99     Av. España 970          1   \n",
       "150787  2019-12-10 12:15:42         99     Av. España 970          0   \n",
       "150788  2019-12-10 18:16:57         99     Av. España 970          1   \n",
       "150789  2019-12-10 18:47:34         99     Av. España 970          0   \n",
       "\n",
       "        lugares_cuadra  ocupacion_max dispon_parq  altas_bajas(dia) operacion  \n",
       "0                 27.0              1       green                 1       NaN  \n",
       "1                 27.0              2       green                 4   Entrada  \n",
       "2                 27.0              2       green                 5    Salida  \n",
       "3                 27.0              2       green                 6   Entrada  \n",
       "4                 27.0              3       green                 7   Entrada  \n",
       "...                ...            ...         ...               ...       ...  \n",
       "150785             NaN              2       green                 8    Salida  \n",
       "150786             NaN              2       green                 9   Entrada  \n",
       "150787             NaN              2       green                11    Salida  \n",
       "150788             NaN              2       green                12   Entrada  \n",
       "150789             NaN              2       green                13    Salida  \n",
       "\n",
       "[150790 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = pd.read_csv(data_w_operacion_path)\n",
    "aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
